{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1664a9a7-c3fd-4082-8bfb-f32f0828cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3654f1-f672-4fa2-a983-1cab1afd0ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>SCZ</th>\n",
       "      <th>BD</th>\n",
       "      <th>MDD</th>\n",
       "      <th>DYX</th>\n",
       "      <th>WR</th>\n",
       "      <th>EA</th>\n",
       "      <th>FI_acc</th>\n",
       "      <th>NM_acc</th>\n",
       "      <th>PM_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>SDS_acc</th>\n",
       "      <th>PM_spd</th>\n",
       "      <th>PRM_spd</th>\n",
       "      <th>RT_spd</th>\n",
       "      <th>SDS_spd</th>\n",
       "      <th>TM_num_spd</th>\n",
       "      <th>TM_anum_spd</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>General</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015</td>\n",
       "      <td>-0.529286</td>\n",
       "      <td>-1.878759</td>\n",
       "      <td>0.107870</td>\n",
       "      <td>-0.170597</td>\n",
       "      <td>-1.606072</td>\n",
       "      <td>-0.279984</td>\n",
       "      <td>-0.916290</td>\n",
       "      <td>-0.803056</td>\n",
       "      <td>-1.335820</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.922212</td>\n",
       "      <td>-0.945486</td>\n",
       "      <td>-0.290518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.086215</td>\n",
       "      <td>-0.365910</td>\n",
       "      <td>-0.758137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000027</td>\n",
       "      <td>-0.340396</td>\n",
       "      <td>-0.002599</td>\n",
       "      <td>-0.013403</td>\n",
       "      <td>-0.539745</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>2.791107</td>\n",
       "      <td>-0.453247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.182794</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.798655</td>\n",
       "      <td>0.176377</td>\n",
       "      <td>-1.298758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.215514</td>\n",
       "      <td>0.460734</td>\n",
       "      <td>-1.074594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000039</td>\n",
       "      <td>1.270266</td>\n",
       "      <td>0.031648</td>\n",
       "      <td>-0.309576</td>\n",
       "      <td>1.304898</td>\n",
       "      <td>-1.502163</td>\n",
       "      <td>0.752067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.413399</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.317901</td>\n",
       "      <td>-0.179128</td>\n",
       "      <td>0.397982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.379332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.644004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442032</td>\n",
       "      <td>-0.926519</td>\n",
       "      <td>-0.181890</td>\n",
       "      <td>0.630429</td>\n",
       "      <td>0.381423</td>\n",
       "      <td>-0.694125</td>\n",
       "      <td>-0.911270</td>\n",
       "      <td>0.349778</td>\n",
       "      <td>-0.509997</td>\n",
       "      <td>-0.380721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000053</td>\n",
       "      <td>0.622400</td>\n",
       "      <td>1.275362</td>\n",
       "      <td>-0.391936</td>\n",
       "      <td>1.077680</td>\n",
       "      <td>-1.360086</td>\n",
       "      <td>-1.020886</td>\n",
       "      <td>-1.842375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.278417</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.113735</td>\n",
       "      <td>0.520546</td>\n",
       "      <td>-0.290518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>-0.632551</td>\n",
       "      <td>-0.520387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498010</th>\n",
       "      <td>6024099</td>\n",
       "      <td>-0.116174</td>\n",
       "      <td>-0.334932</td>\n",
       "      <td>-0.220075</td>\n",
       "      <td>-0.230939</td>\n",
       "      <td>-0.721761</td>\n",
       "      <td>-2.511463</td>\n",
       "      <td>0.472838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.413399</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022833</td>\n",
       "      <td>0.078835</td>\n",
       "      <td>0.550644</td>\n",
       "      <td>0.207821</td>\n",
       "      <td>0.879292</td>\n",
       "      <td>0.643379</td>\n",
       "      <td>0.336162</td>\n",
       "      <td>-0.127401</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>0.769560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498011</th>\n",
       "      <td>6024106</td>\n",
       "      <td>-0.117193</td>\n",
       "      <td>-0.698245</td>\n",
       "      <td>-0.046052</td>\n",
       "      <td>0.569462</td>\n",
       "      <td>-1.733851</td>\n",
       "      <td>-0.354743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.335820</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.801678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.393589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540108</td>\n",
       "      <td>-0.021402</td>\n",
       "      <td>-1.286910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498012</th>\n",
       "      <td>6024112</td>\n",
       "      <td>-0.298949</td>\n",
       "      <td>-0.002036</td>\n",
       "      <td>-0.894351</td>\n",
       "      <td>1.586845</td>\n",
       "      <td>-0.942153</td>\n",
       "      <td>0.487529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739627</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.410141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.379857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.031236</td>\n",
       "      <td>0.132180</td>\n",
       "      <td>0.045081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498013</th>\n",
       "      <td>6024120</td>\n",
       "      <td>-1.120078</td>\n",
       "      <td>-0.217094</td>\n",
       "      <td>0.520356</td>\n",
       "      <td>0.806120</td>\n",
       "      <td>-0.670318</td>\n",
       "      <td>-0.918365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.970232</td>\n",
       "      <td>...</td>\n",
       "      <td>1.216433</td>\n",
       "      <td>1.518965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.319392</td>\n",
       "      <td>1.002620</td>\n",
       "      <td>1.436002</td>\n",
       "      <td>1.427858</td>\n",
       "      <td>-0.392894</td>\n",
       "      <td>-0.009757</td>\n",
       "      <td>1.577710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498014</th>\n",
       "      <td>6024137</td>\n",
       "      <td>0.553774</td>\n",
       "      <td>1.374161</td>\n",
       "      <td>0.040393</td>\n",
       "      <td>-1.542096</td>\n",
       "      <td>1.028158</td>\n",
       "      <td>0.678782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.413399</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.545837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.112700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>-0.668507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498015 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            eid       SCZ        BD       MDD       DYX        WR        EA  \\\n",
       "0       1000015 -0.529286 -1.878759  0.107870 -0.170597 -1.606072 -0.279984   \n",
       "1       1000027 -0.340396 -0.002599 -0.013403 -0.539745  0.907591  2.791107   \n",
       "2       1000039  1.270266  0.031648 -0.309576  1.304898 -1.502163  0.752067   \n",
       "3       1000040       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4       1000053  0.622400  1.275362 -0.391936  1.077680 -1.360086 -1.020886   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "498010  6024099 -0.116174 -0.334932 -0.220075 -0.230939 -0.721761 -2.511463   \n",
       "498011  6024106 -0.117193 -0.698245 -0.046052  0.569462 -1.733851 -0.354743   \n",
       "498012  6024112 -0.298949 -0.002036 -0.894351  1.586845 -0.942153  0.487529   \n",
       "498013  6024120 -1.120078 -0.217094  0.520356  0.806120 -0.670318 -0.918365   \n",
       "498014  6024137  0.553774  1.374161  0.040393 -1.542096  1.028158  0.678782   \n",
       "\n",
       "          FI_acc    NM_acc    PM_acc  ...   SDS_acc    PM_spd   PRM_spd  \\\n",
       "0      -0.916290 -0.803056 -1.335820  ...       NaN -0.922212 -0.945486   \n",
       "1      -0.453247       NaN -0.182794  ...       NaN -1.798655  0.176377   \n",
       "2            NaN       NaN -0.413399  ...       NaN  0.170970       NaN   \n",
       "3      -1.379332       NaN -0.644004  ...  0.442032 -0.926519 -0.181890   \n",
       "4      -1.842375       NaN  0.278417  ...       NaN -0.113735  0.520546   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "498010  0.472838       NaN -0.413399  ...  1.022833  0.078835  0.550644   \n",
       "498011       NaN       NaN -1.335820  ...       NaN -1.801678       NaN   \n",
       "498012       NaN       NaN  0.739627  ...       NaN  0.410141       NaN   \n",
       "498013       NaN       NaN  0.970232  ...  1.216433  1.518965       NaN   \n",
       "498014       NaN       NaN -0.413399  ...       NaN -0.545837       NaN   \n",
       "\n",
       "          RT_spd   SDS_spd  TM_num_spd  TM_anum_spd     Speed  Accuracy  \\\n",
       "0      -0.290518       NaN         NaN          NaN -0.086215 -0.365910   \n",
       "1      -1.298758       NaN         NaN          NaN  1.215514  0.460734   \n",
       "2       0.645269       NaN         NaN          NaN -0.317901 -0.179128   \n",
       "3       0.630429  0.381423   -0.694125    -0.911270  0.349778 -0.509997   \n",
       "4      -0.290518       NaN         NaN          NaN -0.003564 -0.632551   \n",
       "...          ...       ...         ...          ...       ...       ...   \n",
       "498010  0.207821  0.879292    0.643379     0.336162 -0.127401  0.033179   \n",
       "498011 -1.393589       NaN         NaN          NaN  0.540108 -0.021402   \n",
       "498012 -0.379857       NaN         NaN          NaN -0.031236  0.132180   \n",
       "498013  0.319392  1.002620    1.436002     1.427858 -0.392894 -0.009757   \n",
       "498014 -1.112700       NaN         NaN          NaN  0.003831  0.045161   \n",
       "\n",
       "         General  \n",
       "0      -0.758137  \n",
       "1      -1.074594  \n",
       "2       0.397982  \n",
       "3      -0.380721  \n",
       "4      -0.520387  \n",
       "...          ...  \n",
       "498010  0.769560  \n",
       "498011 -1.286910  \n",
       "498012  0.045081  \n",
       "498013  1.577710  \n",
       "498014 -0.668507  \n",
       "\n",
       "[498015 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged_final.tsv', sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad74f111-5caf-415f-9b13-d94a0f9e12a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Significant Correlations (FDR-corrected P < 0.05):\n",
      "Total number of significant correlations: 87\n",
      "\n",
      "Top 10 strongest correlations by absolute value:\n",
      "   Phenotype Cognitive  Spearman_Correlation          FDR_P       N\n",
      "75        EA    FI_acc              0.211400   0.000000e+00  135535\n",
      "0        SCZ    FI_acc             -0.170023   0.000000e+00  135535\n",
      "3        SCZ   PRM_acc             -0.149022   0.000000e+00  140587\n",
      "14       SCZ   General             -0.137120   0.000000e+00  406414\n",
      "30       MDD    FI_acc             -0.132089   0.000000e+00  135535\n",
      "46       DYX    NM_acc             -0.131500  1.554951e-160   41907\n",
      "45       DYX    FI_acc             -0.124520   0.000000e+00  135535\n",
      "18        BD   PRM_acc             -0.121260   0.000000e+00  140587\n",
      "15        BD    FI_acc             -0.120879   0.000000e+00  135535\n",
      "33       MDD   PRM_acc             -0.117231   0.000000e+00  140587\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "def compute_correlation_matrix(data, x_cols, y_cols):\n",
    "    # Initialize results\n",
    "    results = []\n",
    "    \n",
    "    for x in x_cols:\n",
    "        for y in y_cols:\n",
    "            # Get common indices where both columns have non-null values\n",
    "            mask = ~(data[x].isna() | data[y].isna())\n",
    "            if mask.sum() > 0:  # Only compute if we have valid pairs\n",
    "                # Get correlation results\n",
    "                spearman_result = stats.spearmanr(data[x][mask], data[y][mask], nan_policy='omit')\n",
    "                correlation = spearman_result.correlation\n",
    "                pvalue = spearman_result.pvalue\n",
    "                \n",
    "                results.append({\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'correlation': correlation,\n",
    "                    'pvalue': pvalue,\n",
    "                    'n': mask.sum()\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Apply Bonferroni correction using multipletests\n",
    "    corrected_p = multipletests(results_df['pvalue'], method='fdr_bh')[1]\n",
    "    results_df['adjusted_p'] = corrected_p\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Define column groups in specific order\n",
    "phenotype_cols = ['SCZ', 'BD', 'MDD', 'DYX', 'WR', 'EA']  # Already in desired order\n",
    "\n",
    "# Define cognitive measures in specific order\n",
    "cognitive_cols = [\n",
    "    # Accuracy measures\n",
    "    'FI_acc', 'NM_acc', 'PM_acc', 'PRM_acc', 'RT_acc', 'SDS_acc',\n",
    "    # Speed measures\n",
    "    'PM_spd', 'PRM_spd', 'RT_spd', 'SDS_spd', 'TM_num_spd', 'TM_anum_spd',\n",
    "    # Factor scores\n",
    "    'Speed', 'Accuracy', 'General'\n",
    "]\n",
    "\n",
    "# Compute correlations\n",
    "corr_matrix = compute_correlation_matrix(df, phenotype_cols, cognitive_cols)\n",
    "\n",
    "# Create correlation and p-value matrices\n",
    "pivot_corr = corr_matrix.pivot(index='y', columns='x', values='correlation')\n",
    "pivot_p = corr_matrix.pivot(index='y', columns='x', values='adjusted_p')\n",
    "\n",
    "# Reorder the indices and columns to match our desired order\n",
    "pivot_corr = pivot_corr.reindex(index=cognitive_cols, columns=phenotype_cols)\n",
    "pivot_p = pivot_p.reindex(index=cognitive_cols, columns=phenotype_cols)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create heatmap\n",
    "max_corr = np.nanmax(np.abs(pivot_corr.values))\n",
    "sns.heatmap(pivot_corr, \n",
    "            cmap='RdBu_r',\n",
    "            center=0,\n",
    "            vmin=-max_corr,\n",
    "            vmax=max_corr,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={'label': 'Spearman Correlation'},\n",
    "            annot_kws={'size': 8})\n",
    "\n",
    "# Add significance stars\n",
    "for i in range(pivot_corr.shape[0]):\n",
    "    for j in range(pivot_corr.shape[1]):\n",
    "        if not pd.isna(pivot_p.iloc[i, j]):\n",
    "            if pivot_p.iloc[i, j] < 0.001:\n",
    "                sig = '***'\n",
    "            elif pivot_p.iloc[i, j] < 0.01:\n",
    "                sig = '**'\n",
    "            elif pivot_p.iloc[i, j] < 0.05:\n",
    "                sig = '*'\n",
    "            else:\n",
    "                sig = ''\n",
    "                \n",
    "            if sig:\n",
    "                plt.text(j + 0.7, i + 0.5, sig,\n",
    "                        horizontalalignment='left',\n",
    "                        verticalalignment='center',\n",
    "                        color='black',\n",
    "                        fontsize=8)\n",
    "\n",
    "# Add horizontal lines to separate groups\n",
    "plt.axhline(y=6, color='black', linewidth=1)  # After accuracy measures\n",
    "plt.axhline(y=12, color='black', linewidth=1)  # After speed measures\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Phenotype-Cognitive Measure Spearman Correlations\\n(FDR-corrected)', pad=20)\n",
    "plt.xlabel('Phenotypes', labelpad=10)\n",
    "plt.ylabel('Cognitive Measures', labelpad=10)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Adjust layout to prevent cutting off labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "plt.savefig('phenotype_cognitive_correlations_FDR.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Create table of significant correlations\n",
    "significant_correlations = corr_matrix[corr_matrix['adjusted_p'] < 0.05].copy()\n",
    "significant_correlations['significance'] = ''\n",
    "significant_correlations.loc[significant_correlations['adjusted_p'] < 0.05, 'significance'] = '*'\n",
    "significant_correlations.loc[significant_correlations['adjusted_p'] < 0.01, 'significance'] = '**'\n",
    "significant_correlations.loc[significant_correlations['adjusted_p'] < 0.001, 'significance'] = '***'\n",
    "\n",
    "significant_correlations = significant_correlations.rename(columns={\n",
    "    'x': 'Phenotype',\n",
    "    'y': 'Cognitive',\n",
    "    'correlation': 'Spearman_Correlation',\n",
    "    'pvalue': 'P-value',\n",
    "    'adjusted_p': 'FDR_P',\n",
    "    'significance': 'Significance',\n",
    "    'n': 'N'\n",
    "})\n",
    "significant_correlations = significant_correlations.sort_values('FDR_P')\n",
    "\n",
    "# Save to CSV\n",
    "significant_correlations.to_csv('significant_correlations_FDR.csv', index=False)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary of Significant Correlations (FDR-corrected P < 0.05):\")\n",
    "print(f\"Total number of significant correlations: {len(significant_correlations)}\")\n",
    "print(\"\\nTop 10 strongest correlations by absolute value:\")\n",
    "significant_correlations['abs_correlation'] = abs(significant_correlations['Spearman_Correlation'])\n",
    "print(significant_correlations.nlargest(10, 'abs_correlation')[\n",
    "    ['Phenotype', 'Cognitive', 'Spearman_Correlation', 'FDR_P', 'N']\n",
    "].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7337801b-13a6-4cfa-8eb8-9da9b78c107e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4321092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5180505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5457093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4799899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4748722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35916</th>\n",
       "      <td>5718324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35917</th>\n",
       "      <td>4597023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35918</th>\n",
       "      <td>4083151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35919</th>\n",
       "      <td>4518397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35920</th>\n",
       "      <td>1681734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35921 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           eid\n",
       "0      4321092\n",
       "1      5180505\n",
       "2      5457093\n",
       "3      4799899\n",
       "4      4748722\n",
       "...        ...\n",
       "35916  5718324\n",
       "35917  4597023\n",
       "35918  4083151\n",
       "35919  4518397\n",
       "35920  1681734\n",
       "\n",
       "[35921 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psychiatric_diagnosis_df = pd.read_csv('data_participant_psych.tsv', sep=\"\\t\")\n",
    "psychiatric_diagnosis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1d6410f-26b5-45d3-aa4b-b4966d92439f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total psychiatric cases: 35605\n",
      "Cases with DYX PGS: 28666\n",
      "\n",
      "Significant Associations (FDR < 0.05):\n",
      "   Cognitive_Measure      Beta       P_Value         FDR_P      N\n",
      "0             FI_acc -0.115054  8.894711e-31  1.334207e-29   9560\n",
      "13          Accuracy -0.025532  9.260970e-29  6.945727e-28  28616\n",
      "1             NM_acc -0.133478  4.764730e-12  2.382365e-11   3312\n",
      "11       TM_anum_spd -0.068085  1.982294e-05  5.946883e-05   4145\n",
      "14           General -0.019827  1.735347e-05  5.946883e-05  28616\n",
      "2             PM_acc -0.021035  1.570251e-03  3.925626e-03  28587\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def analyze_cognitive_dyslexia(data, psychiatric_eids, cognitive_measures):\n",
    "    \"\"\"\n",
    "    Analyze how DYX PGS predicts cognitive performance in psychiatric cases\n",
    "    \"\"\"\n",
    "    # Create subset of psychiatric cases\n",
    "    psychiatric_cases = data[data['eid'].isin(psychiatric_eids)].copy()\n",
    "    \n",
    "    print(f\"\\nTotal psychiatric cases: {len(psychiatric_cases)}\")\n",
    "    print(f\"Cases with DYX PGS: {psychiatric_cases['DYX'].notna().sum()}\")\n",
    "    \n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "    \n",
    "    # Analyze each cognitive measure\n",
    "    for measure in cognitive_measures:\n",
    "        # Get complete cases for this analysis\n",
    "        valid_data = psychiatric_cases[[measure, 'DYX']].dropna()\n",
    "        \n",
    "        if len(valid_data) < 10:  # Minimum sample size threshold\n",
    "            print(f\"Insufficient data for {measure} (n={len(valid_data)})\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Run regression model\n",
    "            model = sm.OLS(valid_data[measure], \n",
    "                         sm.add_constant(valid_data['DYX'])).fit()\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Cognitive_Measure': measure,\n",
    "                'Beta': model.params['DYX'],\n",
    "                'SE': model.bse['DYX'],\n",
    "                'P_Value': model.pvalues['DYX'],\n",
    "                'R_Squared': model.rsquared,\n",
    "                'N': len(valid_data)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {measure}: {str(e)}\")\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(\"No valid results could be computed\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add FDR correction\n",
    "    results_df['FDR_P'] = multipletests(results_df['P_Value'], method='fdr_bh')[1]\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def create_visualization(results_df, output_file='dyslexia_cognitive_associations.pdf'):\n",
    "    \"\"\"\n",
    "    Create visualization of associations\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Define measure groups\n",
    "    measure_groups = {\n",
    "        'Accuracy': ['FI_acc', 'NM_acc', 'PM_acc', 'PRM_acc', 'RT_acc', 'SDS_acc'],\n",
    "        'Speed': ['PM_spd', 'PRM_spd', 'RT_spd', 'SDS_spd', 'TM_num_spd', 'TM_anum_spd'],\n",
    "        'Factors': ['Speed', 'Accuracy', 'General']\n",
    "    }\n",
    "    \n",
    "    # Add group information\n",
    "    results_df['Measure_Group'] = 'Other'\n",
    "    for group, measures in measure_groups.items():\n",
    "        results_df.loc[results_df['Cognitive_Measure'].isin(measures), 'Measure_Group'] = group\n",
    "    \n",
    "    # Sort by measure group and effect size\n",
    "    results_df['abs_beta'] = abs(results_df['Beta'])\n",
    "    results_df = results_df.sort_values(['Measure_Group', 'abs_beta'])\n",
    "    \n",
    "    # Create forest plot\n",
    "    y_pos = np.arange(len(results_df))\n",
    "    \n",
    "    plt.errorbar(x=results_df['Beta'],\n",
    "                y=y_pos,\n",
    "                xerr=results_df['SE'],\n",
    "                fmt='o',\n",
    "                capsize=5,\n",
    "                color='black',\n",
    "                alpha=0.6)\n",
    "    \n",
    "    # Add points colored by group\n",
    "    for group in measure_groups.keys():\n",
    "        mask = results_df['Measure_Group'] == group\n",
    "        plt.scatter(results_df[mask]['Beta'], \n",
    "                   y_pos[mask], \n",
    "                   label=group,\n",
    "                   s=100,\n",
    "                   zorder=5)\n",
    "    \n",
    "    # Add reference line at zero\n",
    "    plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Add significance markers\n",
    "    for i, row in results_df.iterrows():\n",
    "        if row['FDR_P'] < 0.001:\n",
    "            plt.text(row['Beta'], i, '***', ha='left' if row['Beta'] < 0 else 'right', va='center')\n",
    "        elif row['FDR_P'] < 0.01:\n",
    "            plt.text(row['Beta'], i, '**', ha='left' if row['Beta'] < 0 else 'right', va='center')\n",
    "        elif row['FDR_P'] < 0.05:\n",
    "            plt.text(row['Beta'], i, '*', ha='left' if row['Beta'] < 0 else 'right', va='center')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.yticks(y_pos, results_df['Cognitive_Measure'])\n",
    "    plt.xlabel('Beta Coefficient (DYX PGS)', labelpad=10)\n",
    "    plt.title('Association between Dyslexia PGS and Cognitive Measures\\nin Psychiatric Cases', pad=20)\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(title='Measure Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def main_analysis(df, psychiatric_diagnosis_df):\n",
    "    \"\"\"\n",
    "    Main analysis function\n",
    "    \"\"\"\n",
    "    # Get psychiatric case IDs\n",
    "    psychiatric_eids = psychiatric_diagnosis_df['eid'].unique()\n",
    "    \n",
    "    # Define cognitive measures\n",
    "    cognitive_measures = [\n",
    "        # Accuracy measures\n",
    "        'FI_acc', 'NM_acc', 'PM_acc', 'PRM_acc', 'RT_acc', 'SDS_acc',\n",
    "        # Speed measures\n",
    "        'PM_spd', 'PRM_spd', 'RT_spd', 'SDS_spd', 'TM_num_spd', 'TM_anum_spd',\n",
    "        # Factor scores\n",
    "        'Speed', 'Accuracy', 'General'\n",
    "    ]\n",
    "    \n",
    "    # Run analysis\n",
    "    results = analyze_cognitive_dyslexia(df, psychiatric_eids, cognitive_measures)\n",
    "    \n",
    "    # Create visualization\n",
    "    create_visualization(results)\n",
    "    \n",
    "    # Save detailed results\n",
    "    results.to_csv('dyslexia_cognitive_associations.csv', index=False)\n",
    "    \n",
    "    # Print summary of significant findings\n",
    "    print(\"\\nSignificant Associations (FDR < 0.05):\")\n",
    "    significant = results[results['FDR_P'] < 0.05].sort_values('FDR_P')\n",
    "    if len(significant) > 0:\n",
    "        print(significant[['Cognitive_Measure', 'Beta', 'P_Value', 'FDR_P', 'N']].to_string())\n",
    "    else:\n",
    "        print(\"No significant associations found\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the analysis\n",
    "results = main_analysis(df, psychiatric_diagnosis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a72ce83-69f7-41df-82eb-c34d2b7789a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def create_forest_plot(results_df, output_file='dyslexia_cognitive_associations_revised.pdf'):\n",
    "    # Define the order of measures\n",
    "    accuracy_measures = ['FI_acc', 'NM_acc', 'PM_acc', 'PRM_acc', 'RT_acc', 'SDS_acc']\n",
    "    speed_measures = ['PM_spd', 'PRM_spd', 'RT_spd', 'SDS_spd', 'TM_num_spd', 'TM_anum_spd']\n",
    "    factor_measures = ['Speed', 'Accuracy', 'General']\n",
    "    \n",
    "    # Create measure order\n",
    "    measure_order = accuracy_measures + speed_measures + factor_measures\n",
    "    \n",
    "    # Sort the dataframe\n",
    "    results_df['Measure_Order'] = pd.Categorical(\n",
    "        results_df['Cognitive_Measure'], \n",
    "        categories=measure_order, \n",
    "        ordered=True\n",
    "    )\n",
    "    results_df = results_df.sort_values('Measure_Order')\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plot points and error bars\n",
    "    y_pos = np.arange(len(results_df))\n",
    "    \n",
    "    # Plot error bars\n",
    "    plt.errorbar(x=results_df['Beta'],\n",
    "                y=y_pos,\n",
    "                xerr=results_df['SE'],\n",
    "                fmt='none',\n",
    "                capsize=5,\n",
    "                color='black',\n",
    "                alpha=0.6,\n",
    "                zorder=1)\n",
    "    \n",
    "    # Add points with different colors for each group\n",
    "    colors = {'Accuracy': '#1f77b4', 'Speed': '#2ca02c', 'Factors': '#ff7f0e'}\n",
    "    \n",
    "    for group, color in colors.items():\n",
    "        mask = results_df['Measure_Group'] == group\n",
    "        plt.scatter(results_df[mask]['Beta'], \n",
    "                   y_pos[mask], \n",
    "                   label=group,\n",
    "                   color=color,\n",
    "                   s=100,\n",
    "                   zorder=2)\n",
    "    \n",
    "    # Add vertical line at zero\n",
    "    plt.axvline(x=0, color='gray', linestyle='--', alpha=0.5, zorder=0)\n",
    "    \n",
    "    # Add horizontal lines to separate groups\n",
    "    plt.axhline(y=5.5, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.axhline(y=11.5, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Customize y-axis labels with red for non-significant results\n",
    "    y_labels = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        if row['FDR_P'] >= 0.05:\n",
    "            y_labels.append({'label': row['Cognitive_Measure'], 'color': 'red'})\n",
    "        else:\n",
    "            y_labels.append({'label': row['Cognitive_Measure'], 'color': 'black'})\n",
    "    \n",
    "    plt.yticks(y_pos)\n",
    "    ax = plt.gca()\n",
    "    ax.set_yticklabels([item['label'] for item in y_labels])\n",
    "    for i, tick in enumerate(ax.get_yticklabels()):\n",
    "        tick.set_color(y_labels[i]['color'])\n",
    "    \n",
    "    # Add group labels\n",
    "    plt.text(-0.25, 2.5, 'Accuracy Measures', rotation=90, va='center', ha='right', fontsize=10, fontweight='bold')\n",
    "    plt.text(-0.25, 8.5, 'Speed Measures', rotation=90, va='center', ha='right', fontsize=10, fontweight='bold')\n",
    "    plt.text(-0.25, 13.5, 'Factor Scores', rotation=90, va='center', ha='right', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlabel('Beta Coefficient (DYX PGS)', fontsize=12)\n",
    "    plt.title('Association between Dyslexia PGS and Cognitive Measures\\nin Psychiatric Cases', pad=20, fontsize=14)\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(title='Measure Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Add text note about significance\n",
    "    plt.figtext(0.99, 0.01, 'Red labels indicate non-significant associations (FDR > 0.05)', \n",
    "                ha='right', va='bottom', fontsize=8, style='italic')\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Create the plot using the results dataframe\n",
    "create_forest_plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f22c42e-692b-4d69-a0a1-cc8c5af935b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>Age</th>\n",
       "      <th>sex</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.68480</td>\n",
       "      <td>2.48984</td>\n",
       "      <td>-0.789333</td>\n",
       "      <td>0.085092</td>\n",
       "      <td>-4.93229</td>\n",
       "      <td>1.051890</td>\n",
       "      <td>-0.627460</td>\n",
       "      <td>-0.334926</td>\n",
       "      <td>-1.76369</td>\n",
       "      <td>0.797701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000053</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.16330</td>\n",
       "      <td>2.92919</td>\n",
       "      <td>-2.243640</td>\n",
       "      <td>0.952597</td>\n",
       "      <td>-3.33337</td>\n",
       "      <td>-0.932369</td>\n",
       "      <td>-1.366480</td>\n",
       "      <td>0.158433</td>\n",
       "      <td>-2.69394</td>\n",
       "      <td>1.299870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000132</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.17510</td>\n",
       "      <td>3.03513</td>\n",
       "      <td>-2.020400</td>\n",
       "      <td>-0.546043</td>\n",
       "      <td>-5.84817</td>\n",
       "      <td>-1.924570</td>\n",
       "      <td>0.903956</td>\n",
       "      <td>-0.032164</td>\n",
       "      <td>-3.25403</td>\n",
       "      <td>-1.943640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000148</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.36496</td>\n",
       "      <td>3.67858</td>\n",
       "      <td>-2.469990</td>\n",
       "      <td>4.969160</td>\n",
       "      <td>4.71670</td>\n",
       "      <td>-1.048090</td>\n",
       "      <td>2.688350</td>\n",
       "      <td>-0.837116</td>\n",
       "      <td>-8.29129</td>\n",
       "      <td>1.841580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000163</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.23550</td>\n",
       "      <td>3.77995</td>\n",
       "      <td>-1.684350</td>\n",
       "      <td>10.490100</td>\n",
       "      <td>20.03600</td>\n",
       "      <td>1.751440</td>\n",
       "      <td>-0.396306</td>\n",
       "      <td>0.909707</td>\n",
       "      <td>-2.77910</td>\n",
       "      <td>-3.104170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472571</th>\n",
       "      <td>6023942</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.50680</td>\n",
       "      <td>2.83479</td>\n",
       "      <td>-2.080370</td>\n",
       "      <td>2.355360</td>\n",
       "      <td>-7.89493</td>\n",
       "      <td>-2.146720</td>\n",
       "      <td>2.006970</td>\n",
       "      <td>-0.999976</td>\n",
       "      <td>-1.45081</td>\n",
       "      <td>0.963057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472572</th>\n",
       "      <td>6024045</td>\n",
       "      <td>64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-12.02210</td>\n",
       "      <td>3.38163</td>\n",
       "      <td>0.574447</td>\n",
       "      <td>2.077890</td>\n",
       "      <td>-5.38070</td>\n",
       "      <td>1.106630</td>\n",
       "      <td>0.797963</td>\n",
       "      <td>-3.702040</td>\n",
       "      <td>1.52908</td>\n",
       "      <td>6.244980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472573</th>\n",
       "      <td>6024074</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.82170</td>\n",
       "      <td>2.09487</td>\n",
       "      <td>-1.532360</td>\n",
       "      <td>2.130450</td>\n",
       "      <td>-1.86970</td>\n",
       "      <td>1.635820</td>\n",
       "      <td>0.063636</td>\n",
       "      <td>0.888297</td>\n",
       "      <td>-1.56323</td>\n",
       "      <td>0.310647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472574</th>\n",
       "      <td>6024106</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.49980</td>\n",
       "      <td>3.66671</td>\n",
       "      <td>-1.412420</td>\n",
       "      <td>1.727630</td>\n",
       "      <td>-2.24667</td>\n",
       "      <td>-2.290800</td>\n",
       "      <td>-0.992355</td>\n",
       "      <td>-0.873021</td>\n",
       "      <td>2.53544</td>\n",
       "      <td>1.824300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472575</th>\n",
       "      <td>6024120</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.80880</td>\n",
       "      <td>6.12301</td>\n",
       "      <td>-0.459131</td>\n",
       "      <td>-0.323569</td>\n",
       "      <td>-6.24753</td>\n",
       "      <td>-1.153880</td>\n",
       "      <td>1.977510</td>\n",
       "      <td>-2.375610</td>\n",
       "      <td>1.41007</td>\n",
       "      <td>-1.823070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472576 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            eid  Age  sex       PC1      PC2       PC3        PC4       PC5  \\\n",
       "0       1000015   66  0.0 -12.68480  2.48984 -0.789333   0.085092  -4.93229   \n",
       "1       1000053   62  0.0 -11.16330  2.92919 -2.243640   0.952597  -3.33337   \n",
       "2       1000132   41  0.0 -14.17510  3.03513 -2.020400  -0.546043  -5.84817   \n",
       "3       1000148   48  0.0  -9.36496  3.67858 -2.469990   4.969160   4.71670   \n",
       "4       1000163   42  0.0 -14.23550  3.77995 -1.684350  10.490100  20.03600   \n",
       "...         ...  ...  ...       ...      ...       ...        ...       ...   \n",
       "472571  6023942   61  0.0 -15.50680  2.83479 -2.080370   2.355360  -7.89493   \n",
       "472572  6024045   64  1.0 -12.02210  3.38163  0.574447   2.077890  -5.38070   \n",
       "472573  6024074   62  0.0 -12.82170  2.09487 -1.532360   2.130450  -1.86970   \n",
       "472574  6024106   65  0.0 -13.49980  3.66671 -1.412420   1.727630  -2.24667   \n",
       "472575  6024120   41  0.0 -10.80880  6.12301 -0.459131  -0.323569  -6.24753   \n",
       "\n",
       "             PC6       PC7       PC8      PC9      PC10  \n",
       "0       1.051890 -0.627460 -0.334926 -1.76369  0.797701  \n",
       "1      -0.932369 -1.366480  0.158433 -2.69394  1.299870  \n",
       "2      -1.924570  0.903956 -0.032164 -3.25403 -1.943640  \n",
       "3      -1.048090  2.688350 -0.837116 -8.29129  1.841580  \n",
       "4       1.751440 -0.396306  0.909707 -2.77910 -3.104170  \n",
       "...          ...       ...       ...      ...       ...  \n",
       "472571 -2.146720  2.006970 -0.999976 -1.45081  0.963057  \n",
       "472572  1.106630  0.797963 -3.702040  1.52908  6.244980  \n",
       "472573  1.635820  0.063636  0.888297 -1.56323  0.310647  \n",
       "472574 -2.290800 -0.992355 -0.873021  2.53544  1.824300  \n",
       "472575 -1.153880  1.977510 -2.375610  1.41007 -1.823070  \n",
       "\n",
       "[472576 rows x 13 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_df = pd.read_csv('../all_participants_wo_head.tsv', sep=\"\\t\", header = None, names = [\"eid\", \"Age\", \"sex\", \"PC1\", \"PC2\", \"PC3\",\n",
    "                                                                   \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\"])\n",
    "cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87153aca-6fbf-4d51-b0c0-c1d0c73fa020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total psychiatric cases after merging covariates: 33883\n",
      "Cases with complete covariate data: 32759\n",
      "\n",
      "Significant Associations (FDR < 0.05):\n",
      "   Cognitive_Measure      Beta       P_Value         FDR_P      N  R_Squared\n",
      "0             FI_acc -0.103796  1.889835e-24  2.834753e-23   8942   0.013534\n",
      "13          Accuracy -0.021094  4.321207e-20  3.240905e-19  26944   0.006446\n",
      "1             NM_acc -0.122207  1.823054e-10  9.115268e-10   3143   0.016903\n",
      "11       TM_anum_spd -0.070510  4.181069e-06  1.567901e-05   4008   0.109923\n",
      "14           General -0.012754  3.385366e-03  1.015610e-02  26944   0.119590\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def analyze_cognitive_dyslexia_with_covariates(data, psychiatric_eids, cognitive_measures, covariates_df):\n",
    "    \"\"\"\n",
    "    Analyze how DYX PGS predicts cognitive performance in psychiatric cases, controlling for covariates\n",
    "    \"\"\"\n",
    "    # Merge main data with covariates\n",
    "    data_with_cov = data.merge(covariates_df, on='eid', how='inner')\n",
    "    \n",
    "    # Create subset of psychiatric cases\n",
    "    psychiatric_cases = data_with_cov[data_with_cov['eid'].isin(psychiatric_eids)].copy()\n",
    "    \n",
    "    print(f\"\\nTotal psychiatric cases after merging covariates: {len(psychiatric_cases)}\")\n",
    "    print(f\"Cases with complete covariate data: {psychiatric_cases.dropna(subset=['Age', 'sex'] + [f'PC{i}' for i in range(1,11)]).shape[0]}\")\n",
    "    \n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "    \n",
    "    # Covariate columns\n",
    "    covariate_cols = ['Age', 'sex'] #+ [f'PC{i}' for i in range(1,11)]\n",
    "    \n",
    "    # Analyze each cognitive measure\n",
    "    for measure in cognitive_measures:\n",
    "        # Get complete cases for this analysis\n",
    "        valid_data = psychiatric_cases[[measure, 'DYX'] + covariate_cols].dropna()\n",
    "        \n",
    "        if len(valid_data) < 10:  # Minimum sample size threshold\n",
    "            print(f\"Insufficient data for {measure} (n={len(valid_data)})\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Prepare predictors (DYX + covariates)\n",
    "            X = valid_data[['DYX'] + covariate_cols]\n",
    "            X = sm.add_constant(X)\n",
    "            y = valid_data[measure]\n",
    "            \n",
    "            # Run regression model\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            \n",
    "            # Store results for DYX\n",
    "            results.append({\n",
    "                'Cognitive_Measure': measure,\n",
    "                'Beta': model.params['DYX'],\n",
    "                'SE': model.bse['DYX'],\n",
    "                'P_Value': model.pvalues['DYX'],\n",
    "                'R_Squared': model.rsquared,\n",
    "                'N': len(valid_data)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {measure}: {str(e)}\")\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(\"No valid results could be computed\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add FDR correction\n",
    "    results_df['FDR_P'] = multipletests(results_df['P_Value'], method='fdr_bh')[1]\n",
    "    \n",
    "    # Add measure grouping\n",
    "    results_df['Measure_Group'] = 'Other'\n",
    "    results_df.loc[results_df['Cognitive_Measure'].str.contains('_acc'), 'Measure_Group'] = 'Accuracy'\n",
    "    results_df.loc[results_df['Cognitive_Measure'].str.contains('_spd'), 'Measure_Group'] = 'Speed'\n",
    "    results_df.loc[results_df['Cognitive_Measure'].isin(['Speed', 'Accuracy', 'General']), 'Measure_Group'] = 'Factors'\n",
    "    \n",
    "    # Add absolute beta for sorting\n",
    "    results_df['abs_beta'] = abs(results_df['Beta'])\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def main_analysis(df, psychiatric_diagnosis_df, cov_df):\n",
    "    \"\"\"\n",
    "    Main analysis function with covariates\n",
    "    \"\"\"\n",
    "    # Get psychiatric case IDs\n",
    "    psychiatric_eids = psychiatric_diagnosis_df['eid'].unique()\n",
    "    \n",
    "    # Define cognitive measures\n",
    "    cognitive_measures = [\n",
    "        # Accuracy measures\n",
    "        'FI_acc', 'NM_acc', 'PM_acc', 'PRM_acc', 'RT_acc', 'SDS_acc',\n",
    "        # Speed measures\n",
    "        'PM_spd', 'PRM_spd', 'RT_spd', 'SDS_spd', 'TM_num_spd', 'TM_anum_spd',\n",
    "        # Factor scores\n",
    "        'Speed', 'Accuracy', 'General'\n",
    "    ]\n",
    "    \n",
    "    # Run analysis with covariates\n",
    "    results = analyze_cognitive_dyslexia_with_covariates(df, psychiatric_eids, cognitive_measures, cov_df)\n",
    "    \n",
    "    # Save detailed results\n",
    "    results.to_csv('dyslexia_cognitive_associations_with_covariates.csv', index=False)\n",
    "    \n",
    "    # Print summary of significant findings\n",
    "    print(\"\\nSignificant Associations (FDR < 0.05):\")\n",
    "    significant = results[results['FDR_P'] < 0.05].sort_values('FDR_P')\n",
    "    if len(significant) > 0:\n",
    "        print(significant[['Cognitive_Measure', 'Beta', 'P_Value', 'FDR_P', 'N', 'R_Squared']].to_string())\n",
    "    else:\n",
    "        print(\"No significant associations found\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the analysis\n",
    "results = main_analysis(df, psychiatric_diagnosis_df, cov_df)\n",
    "\n",
    "# Create visualization (using the previously defined function)\n",
    "create_forest_plot(results, 'dyslexia_cognitive_associations_with_covariates.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
